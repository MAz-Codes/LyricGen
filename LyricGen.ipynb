{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LyricGen is supposed to receive prompts (later features/conditions delivered externally) give back lyrics in the style of my own lyrics. Trained on my texts, lyrics and poems, it should generate in-style lyrics responding to the semantic category of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "config = GPT2Config.from_pretrained('gpt2', output_hidden_states=False, output_attentions=False)\n",
    "config.dropout = 0.1\n",
    "config.weight_decay = 0.01\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current model is performing almost as expected. It seems to be slightly over-fitted, therefore I need to clean the data first to see if that's the case. The data used is only being utilized as an example and must go through further detailed examination and categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.3309534788131714\n",
      "Epoch: 1, Loss: 1.042212724685669\n",
      "Epoch: 2, Loss: 0.8647075295448303\n",
      "Epoch: 3, Loss: 0.6951726675033569\n",
      "Epoch: 4, Loss: 0.5014137625694275\n",
      "Epoch: 5, Loss: 0.38607585430145264\n",
      "Epoch: 6, Loss: 0.22857137024402618\n",
      "Epoch: 7, Loss: 0.13879910111427307\n",
      "Epoch: 8, Loss: 0.06386864930391312\n",
      "Epoch: 9, Loss: 0.08561265468597412\n",
      "Epoch: 10, Loss: 0.06267499923706055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('semantic-lyrics-pairs.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "lyrics = [' '.join(item['lyrics']) for item in data]\n",
    "\n",
    "inputs = tokenizer(lyrics, return_tensors='pt', truncation=True, padding=True)\n",
    "dataset = torch.utils.data.TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range (11):\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Should save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./\n"
     ]
    }
   ],
   "source": [
    "model_path = './'  \n",
    "\n",
    "\n",
    "model.save_pretrained(model_path)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test is performing very poorly.\n",
    "\n",
    "Theory:\n",
    "1- Data labeling is horrible (which is)\n",
    "2- Data quality is very low\n",
    "3- Adjective diversity is very poor\n",
    "\n",
    "Solution:\n",
    "1- Clean Data?\n",
    "2- More Data?\n",
    "3- Check if the semantic tag is being recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.348606765270233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('test-lyrics.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_lyrics = [' '.join(item['lyrics']) for item in test_data]\n",
    "test_inputs = tokenizer(test_lyrics, return_tensors='pt', truncation=True, padding=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2)\n",
    "\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        input_ids, attention_mask = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        total_test_loss += outputs.loss.item()\n",
    "\n",
    "average_test_loss = total_test_loss / len(test_dataloader)\n",
    "\n",
    "print(f\"Test Loss: {average_test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It all \n",
      "We come pure and somehow blue \n",
      "Let go of all \n",
      "That we belong \n",
      "With all that we should've taken care of \n",
      "And hoped that somehow... \n",
      "Nothing will happen \n",
      "If we take farthing \n",
      "For nothing, forever\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hope\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    "    attention_mask=attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=2.0\n",
    ")\n",
    "\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "generated_text = generated_text[len(prompt):].lstrip()\n",
    "generated_text = generated_text[0].upper() + generated_text[1:]\n",
    "\n",
    "\n",
    "formatted_text = re.sub(r'(?<!^)(?<!\\n)(?=[A-Z])', '\\n', generated_text)\n",
    "\n",
    "print(formatted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
